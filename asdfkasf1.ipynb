{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQCrDGvLUxYx",
        "outputId": "b7afc9c7-fca5-47bf-fee3-7399ba46ebff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (1.23.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "p4Su4Uw9RE3B",
        "outputId": "9bb7ac14-4dd9-4051-dd70-5f8e2fb538d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23\n",
            "  Downloading numpy-1.23.0.tar.gz (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: numpy\n",
            "  Building wheel for numpy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpy: filename=numpy-1.23.0-cp311-cp311-linux_x86_64.whl size=19729869 sha256=62dd2716d98eb8481f41833fe762567ba4dc696da5c05d1f567aed3df16d90cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/36/1a/3ec6b85008bea3151efb003f5d41baa7bf4966cb43c1c2470b\n",
            "Successfully built numpy\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.0 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.0 which is incompatible.\n",
            "pandas 2.2.2 requires numpy>=1.23.2; python_version == \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.0 which is incompatible.\n",
            "dm-tree 0.1.9 requires numpy>=1.23.3; python_version >= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
            "bigframes 2.8.0 requires numpy>=1.24.0, but you have numpy 1.23.0 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.0 which is incompatible.\n",
            "plotnine 0.14.6 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
            "opencv-python-headless 4.11.0.86 requires numpy>=1.23.5; python_version >= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
            "astropy 7.1.0 requires numpy>=1.23.2, but you have numpy 1.23.0 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.0 which is incompatible.\n",
            "scipy 1.15.3 requires numpy<2.5,>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.0 which is incompatible.\n",
            "mizani 0.13.5 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.0 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.0 which is incompatible.\n",
            "flax 0.10.6 requires numpy>=1.23.2; python_version >= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.0 which is incompatible.\n",
            "ml-dtypes 0.4.1 requires numpy>=1.23.3; python_version >= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
            "opencv-contrib-python 4.11.0.86 requires numpy>=1.23.5; python_version >= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
            "blosc2 3.5.0 requires numpy>=1.26, but you have numpy 1.23.0 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.0 which is incompatible.\n",
            "opencv-python 4.11.0.86 requires numpy>=1.23.5; python_version >= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "40171cc153844ba08d6037df857bd813"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b02nE-2HK669",
        "outputId": "dd78da7d-8755-4611-cfa5-6347a1ab0e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1: Total Reward = -191.50, Epsilon = 0.980\n",
            "Episode 2: Total Reward = -191.81, Epsilon = 0.960\n",
            "Episode 3: Total Reward = -180.08, Epsilon = 0.941\n",
            "Episode 4: Total Reward = -185.51, Epsilon = 0.922\n",
            "Episode 5: Total Reward = -173.95, Epsilon = 0.904\n",
            "Episode 6: Total Reward = -190.13, Epsilon = 0.886\n",
            "Episode 7: Total Reward = -193.83, Epsilon = 0.868\n",
            "Episode 8: Total Reward = -179.86, Epsilon = 0.851\n",
            "Episode 9: Total Reward = -179.92, Epsilon = 0.834\n",
            "Episode 10: Total Reward = -192.83, Epsilon = 0.817\n",
            "Episode 11: Total Reward = -182.05, Epsilon = 0.801\n",
            "Episode 12: Total Reward = -168.48, Epsilon = 0.785\n",
            "Episode 13: Total Reward = -177.52, Epsilon = 0.769\n",
            "Episode 14: Total Reward = -190.79, Epsilon = 0.754\n",
            "Episode 15: Total Reward = -184.68, Epsilon = 0.739\n",
            "Episode 16: Total Reward = -189.49, Epsilon = 0.724\n",
            "Episode 17: Total Reward = -189.40, Epsilon = 0.709\n",
            "Episode 18: Total Reward = -186.51, Epsilon = 0.695\n",
            "Episode 19: Total Reward = -190.40, Epsilon = 0.681\n",
            "Episode 20: Total Reward = -192.02, Epsilon = 0.668\n",
            "Episode 21: Total Reward = -186.44, Epsilon = 0.654\n",
            "Episode 22: Total Reward = -195.86, Epsilon = 0.641\n",
            "Episode 23: Total Reward = -182.05, Epsilon = 0.628\n",
            "Episode 24: Total Reward = -193.31, Epsilon = 0.616\n",
            "Episode 25: Total Reward = -179.14, Epsilon = 0.603\n",
            "Episode 26: Total Reward = -188.95, Epsilon = 0.591\n",
            "Episode 27: Total Reward = -193.67, Epsilon = 0.580\n",
            "Episode 28: Total Reward = -189.70, Epsilon = 0.568\n",
            "Episode 29: Total Reward = -185.86, Epsilon = 0.557\n",
            "Episode 30: Total Reward = -184.44, Epsilon = 0.545\n",
            "Episode 31: Total Reward = -178.69, Epsilon = 0.535\n",
            "Episode 32: Total Reward = -194.38, Epsilon = 0.524\n",
            "Episode 33: Total Reward = -175.39, Epsilon = 0.513\n",
            "Episode 34: Total Reward = -155.13, Epsilon = 0.503\n",
            "Episode 35: Total Reward = -180.37, Epsilon = 0.493\n",
            "Episode 36: Total Reward = -181.96, Epsilon = 0.483\n",
            "Episode 37: Total Reward = -187.73, Epsilon = 0.474\n",
            "Episode 38: Total Reward = -178.04, Epsilon = 0.464\n",
            "Episode 39: Total Reward = -169.72, Epsilon = 0.455\n",
            "Episode 40: Total Reward = -180.42, Epsilon = 0.446\n",
            "Episode 41: Total Reward = -187.09, Epsilon = 0.437\n",
            "Episode 42: Total Reward = -190.06, Epsilon = 0.428\n",
            "Episode 43: Total Reward = -189.92, Epsilon = 0.419\n",
            "Episode 44: Total Reward = -167.32, Epsilon = 0.411\n",
            "Episode 45: Total Reward = -183.61, Epsilon = 0.403\n",
            "Episode 46: Total Reward = -177.00, Epsilon = 0.395\n",
            "Episode 47: Total Reward = -182.19, Epsilon = 0.387\n",
            "Episode 48: Total Reward = -168.50, Epsilon = 0.379\n",
            "Episode 49: Total Reward = -169.92, Epsilon = 0.372\n",
            "Episode 50: Total Reward = -176.55, Epsilon = 0.364\n",
            "Episode 51: Total Reward = -178.90, Epsilon = 0.357\n",
            "Episode 52: Total Reward = -181.82, Epsilon = 0.350\n",
            "Episode 53: Total Reward = -174.81, Epsilon = 0.343\n",
            "Episode 54: Total Reward = -170.26, Epsilon = 0.336\n",
            "Episode 55: Total Reward = -164.35, Epsilon = 0.329\n",
            "Episode 56: Total Reward = -175.93, Epsilon = 0.323\n",
            "Episode 57: Total Reward = -159.55, Epsilon = 0.316\n",
            "Episode 58: Total Reward = -181.51, Epsilon = 0.310\n",
            "Episode 59: Total Reward = -182.75, Epsilon = 0.304\n",
            "Episode 60: Total Reward = -177.76, Epsilon = 0.298\n",
            "Episode 61: Total Reward = -178.53, Epsilon = 0.292\n",
            "Episode 62: Total Reward = -188.11, Epsilon = 0.286\n",
            "Episode 63: Total Reward = -169.66, Epsilon = 0.280\n",
            "Episode 64: Total Reward = -187.28, Epsilon = 0.274\n",
            "Episode 65: Total Reward = -181.36, Epsilon = 0.269\n",
            "Episode 66: Total Reward = -186.40, Epsilon = 0.264\n",
            "Episode 67: Total Reward = -166.16, Epsilon = 0.258\n",
            "Episode 68: Total Reward = -171.08, Epsilon = 0.253\n",
            "Episode 69: Total Reward = -181.49, Epsilon = 0.248\n",
            "Episode 70: Total Reward = -153.83, Epsilon = 0.243\n",
            "Episode 71: Total Reward = -107.65, Epsilon = 0.238\n",
            "Episode 72: Total Reward = -157.89, Epsilon = 0.233\n",
            "Episode 73: Total Reward = -178.01, Epsilon = 0.229\n",
            "Episode 74: Total Reward = -156.22, Epsilon = 0.224\n",
            "Episode 75: Total Reward = -169.68, Epsilon = 0.220\n",
            "Episode 76: Total Reward = -168.98, Epsilon = 0.215\n",
            "Episode 77: Total Reward = -185.45, Epsilon = 0.211\n",
            "Episode 78: Total Reward = -177.85, Epsilon = 0.207\n",
            "Episode 79: Total Reward = -179.00, Epsilon = 0.203\n",
            "Episode 80: Total Reward = -186.67, Epsilon = 0.199\n",
            "Episode 81: Total Reward = -155.93, Epsilon = 0.195\n",
            "Episode 82: Total Reward = -181.08, Epsilon = 0.191\n",
            "Episode 83: Total Reward = -141.11, Epsilon = 0.187\n",
            "Episode 84: Total Reward = -176.67, Epsilon = 0.183\n",
            "Episode 85: Total Reward = -152.27, Epsilon = 0.180\n",
            "Episode 86: Total Reward = -119.28, Epsilon = 0.176\n",
            "Episode 87: Total Reward = -171.77, Epsilon = 0.172\n",
            "Episode 88: Total Reward = -175.35, Epsilon = 0.169\n",
            "Episode 89: Total Reward = -165.25, Epsilon = 0.166\n",
            "Episode 90: Total Reward = -177.53, Epsilon = 0.162\n",
            "Episode 91: Total Reward = -185.19, Epsilon = 0.159\n",
            "Episode 92: Total Reward = -168.14, Epsilon = 0.156\n",
            "Episode 93: Total Reward = -150.85, Epsilon = 0.153\n",
            "Episode 94: Total Reward = -172.17, Epsilon = 0.150\n",
            "Episode 95: Total Reward = -149.32, Epsilon = 0.147\n",
            "Episode 96: Total Reward = -154.90, Epsilon = 0.144\n",
            "Episode 97: Total Reward = -169.57, Epsilon = 0.141\n",
            "Episode 98: Total Reward = -177.72, Epsilon = 0.138\n",
            "Episode 99: Total Reward = -168.66, Epsilon = 0.135\n",
            "Episode 100: Total Reward = -181.21, Epsilon = 0.133\n",
            "Episode 101: Total Reward = -175.99, Epsilon = 0.130\n",
            "Episode 102: Total Reward = -155.99, Epsilon = 0.127\n",
            "Episode 103: Total Reward = -179.44, Epsilon = 0.125\n",
            "Episode 104: Total Reward = -95.61, Epsilon = 0.122\n",
            "Episode 105: Total Reward = -183.52, Epsilon = 0.120\n",
            "Episode 106: Total Reward = -173.54, Epsilon = 0.117\n",
            "Episode 107: Total Reward = -149.29, Epsilon = 0.115\n",
            "Episode 108: Total Reward = -172.12, Epsilon = 0.113\n",
            "Episode 109: Total Reward = -181.99, Epsilon = 0.111\n",
            "Episode 110: Total Reward = -167.02, Epsilon = 0.108\n",
            "Episode 111: Total Reward = -181.82, Epsilon = 0.106\n",
            "Episode 112: Total Reward = -173.26, Epsilon = 0.104\n",
            "Episode 113: Total Reward = -174.43, Epsilon = 0.102\n",
            "Episode 114: Total Reward = -179.23, Epsilon = 0.100\n",
            "Episode 115: Total Reward = -156.53, Epsilon = 0.098\n",
            "Episode 116: Total Reward = -176.24, Epsilon = 0.096\n",
            "Episode 117: Total Reward = -169.18, Epsilon = 0.094\n",
            "Episode 118: Total Reward = -177.40, Epsilon = 0.092\n",
            "Episode 119: Total Reward = -186.86, Epsilon = 0.090\n",
            "Episode 120: Total Reward = -164.89, Epsilon = 0.089\n",
            "Episode 121: Total Reward = -157.65, Epsilon = 0.087\n",
            "Episode 122: Total Reward = -168.32, Epsilon = 0.085\n",
            "Episode 123: Total Reward = -175.01, Epsilon = 0.083\n",
            "Episode 124: Total Reward = -178.52, Epsilon = 0.082\n",
            "Episode 125: Total Reward = -162.76, Epsilon = 0.080\n",
            "Episode 126: Total Reward = -171.11, Epsilon = 0.078\n",
            "Episode 127: Total Reward = -137.52, Epsilon = 0.077\n",
            "Episode 128: Total Reward = -149.35, Epsilon = 0.075\n",
            "Episode 129: Total Reward = -164.02, Epsilon = 0.074\n",
            "Episode 130: Total Reward = -178.03, Epsilon = 0.072\n",
            "Episode 131: Total Reward = -91.41, Epsilon = 0.071\n",
            "Episode 132: Total Reward = -179.49, Epsilon = 0.069\n",
            "Episode 133: Total Reward = -158.25, Epsilon = 0.068\n",
            "Episode 134: Total Reward = -161.67, Epsilon = 0.067\n",
            "Episode 135: Total Reward = -169.93, Epsilon = 0.065\n",
            "Episode 136: Total Reward = -179.80, Epsilon = 0.064\n",
            "Episode 137: Total Reward = -179.21, Epsilon = 0.063\n",
            "Episode 138: Total Reward = -167.21, Epsilon = 0.062\n",
            "Episode 139: Total Reward = -168.40, Epsilon = 0.060\n",
            "Episode 140: Total Reward = -179.91, Epsilon = 0.059\n",
            "Episode 141: Total Reward = -181.17, Epsilon = 0.058\n",
            "Episode 142: Total Reward = -156.22, Epsilon = 0.057\n",
            "Episode 143: Total Reward = -158.06, Epsilon = 0.056\n",
            "Episode 144: Total Reward = -130.45, Epsilon = 0.055\n",
            "Episode 145: Total Reward = -167.72, Epsilon = 0.053\n",
            "Episode 146: Total Reward = -124.02, Epsilon = 0.052\n",
            "Episode 147: Total Reward = -177.13, Epsilon = 0.051\n",
            "Episode 148: Total Reward = -173.77, Epsilon = 0.050\n",
            "Episode 149: Total Reward = -60.77, Epsilon = 0.050\n",
            "Episode 150: Total Reward = -162.71, Epsilon = 0.050\n",
            "Episode 151: Total Reward = -153.62, Epsilon = 0.050\n",
            "Episode 152: Total Reward = -155.23, Epsilon = 0.050\n",
            "Episode 153: Total Reward = -168.24, Epsilon = 0.050\n",
            "Episode 154: Total Reward = -142.90, Epsilon = 0.050\n",
            "Episode 155: Total Reward = -134.89, Epsilon = 0.050\n",
            "Episode 156: Total Reward = -137.13, Epsilon = 0.050\n",
            "Episode 157: Total Reward = -167.23, Epsilon = 0.050\n",
            "Episode 158: Total Reward = -150.11, Epsilon = 0.050\n",
            "Episode 159: Total Reward = -125.31, Epsilon = 0.050\n",
            "Episode 160: Total Reward = -173.76, Epsilon = 0.050\n",
            "Episode 161: Total Reward = -126.76, Epsilon = 0.050\n",
            "Episode 162: Total Reward = -168.16, Epsilon = 0.050\n",
            "Episode 163: Total Reward = -164.39, Epsilon = 0.050\n",
            "Episode 164: Total Reward = -148.68, Epsilon = 0.050\n",
            "Episode 165: Total Reward = -173.37, Epsilon = 0.050\n",
            "Episode 166: Total Reward = -137.27, Epsilon = 0.050\n",
            "Episode 167: Total Reward = -59.16, Epsilon = 0.050\n",
            "Episode 168: Total Reward = -115.60, Epsilon = 0.050\n",
            "Episode 169: Total Reward = -167.11, Epsilon = 0.050\n",
            "Episode 170: Total Reward = -136.97, Epsilon = 0.050\n",
            "Episode 171: Total Reward = -149.72, Epsilon = 0.050\n",
            "Episode 172: Total Reward = -147.29, Epsilon = 0.050\n",
            "Episode 173: Total Reward = -151.72, Epsilon = 0.050\n",
            "Episode 174: Total Reward = -163.05, Epsilon = 0.050\n",
            "Episode 175: Total Reward = -173.42, Epsilon = 0.050\n",
            "Episode 176: Total Reward = -145.99, Epsilon = 0.050\n",
            "Episode 177: Total Reward = -139.57, Epsilon = 0.050\n",
            "Episode 178: Total Reward = -168.53, Epsilon = 0.050\n",
            "Episode 179: Total Reward = -166.62, Epsilon = 0.050\n",
            "Episode 180: Total Reward = -159.96, Epsilon = 0.050\n",
            "Episode 181: Total Reward = -160.62, Epsilon = 0.050\n",
            "Episode 182: Total Reward = -159.93, Epsilon = 0.050\n",
            "Episode 183: Total Reward = -130.93, Epsilon = 0.050\n",
            "Episode 184: Total Reward = -169.71, Epsilon = 0.050\n",
            "Episode 185: Total Reward = -167.43, Epsilon = 0.050\n",
            "Episode 186: Total Reward = -149.50, Epsilon = 0.050\n",
            "Episode 187: Total Reward = -176.24, Epsilon = 0.050\n",
            "Episode 188: Total Reward = -169.07, Epsilon = 0.050\n",
            "Episode 189: Total Reward = -158.73, Epsilon = 0.050\n",
            "Episode 190: Total Reward = -170.61, Epsilon = 0.050\n",
            "Episode 191: Total Reward = -169.78, Epsilon = 0.050\n",
            "Episode 192: Total Reward = -172.23, Epsilon = 0.050\n",
            "Episode 193: Total Reward = -149.64, Epsilon = 0.050\n",
            "Episode 194: Total Reward = -158.33, Epsilon = 0.050\n",
            "Episode 195: Total Reward = -169.41, Epsilon = 0.050\n",
            "Episode 196: Total Reward = -170.63, Epsilon = 0.050\n",
            "Episode 197: Total Reward = -167.03, Epsilon = 0.050\n",
            "Episode 198: Total Reward = -168.83, Epsilon = 0.050\n",
            "Episode 199: Total Reward = -162.77, Epsilon = 0.050\n",
            "Episode 200: Total Reward = -172.22, Epsilon = 0.050\n",
            "Episode 201: Total Reward = -180.02, Epsilon = 0.050\n",
            "Episode 202: Total Reward = -169.66, Epsilon = 0.050\n",
            "Episode 203: Total Reward = -172.30, Epsilon = 0.050\n",
            "Episode 204: Total Reward = -158.37, Epsilon = 0.050\n",
            "Episode 205: Total Reward = -166.30, Epsilon = 0.050\n",
            "Episode 206: Total Reward = -150.74, Epsilon = 0.050\n",
            "Episode 207: Total Reward = -166.61, Epsilon = 0.050\n",
            "Episode 208: Total Reward = -151.24, Epsilon = 0.050\n",
            "Episode 209: Total Reward = -166.71, Epsilon = 0.050\n",
            "Episode 210: Total Reward = -161.22, Epsilon = 0.050\n",
            "Episode 211: Total Reward = -172.59, Epsilon = 0.050\n",
            "Episode 212: Total Reward = -161.14, Epsilon = 0.050\n",
            "Episode 213: Total Reward = -176.15, Epsilon = 0.050\n",
            "Episode 214: Total Reward = -146.05, Epsilon = 0.050\n",
            "Episode 215: Total Reward = -165.43, Epsilon = 0.050\n",
            "Episode 216: Total Reward = -181.86, Epsilon = 0.050\n",
            "Episode 217: Total Reward = -140.51, Epsilon = 0.050\n",
            "Episode 218: Total Reward = -177.19, Epsilon = 0.050\n",
            "Episode 219: Total Reward = -150.58, Epsilon = 0.050\n",
            "Episode 220: Total Reward = -158.32, Epsilon = 0.050\n",
            "Episode 221: Total Reward = -176.52, Epsilon = 0.050\n",
            "Episode 222: Total Reward = -152.56, Epsilon = 0.050\n",
            "Episode 223: Total Reward = -163.88, Epsilon = 0.050\n",
            "Episode 224: Total Reward = -167.28, Epsilon = 0.050\n",
            "Episode 225: Total Reward = -161.74, Epsilon = 0.050\n",
            "Episode 226: Total Reward = -154.03, Epsilon = 0.050\n",
            "Episode 227: Total Reward = -176.50, Epsilon = 0.050\n",
            "Episode 228: Total Reward = -175.43, Epsilon = 0.050\n",
            "Episode 229: Total Reward = -158.81, Epsilon = 0.050\n",
            "Episode 230: Total Reward = -170.70, Epsilon = 0.050\n",
            "Episode 231: Total Reward = -144.58, Epsilon = 0.050\n",
            "Episode 232: Total Reward = -168.99, Epsilon = 0.050\n",
            "Episode 233: Total Reward = -141.90, Epsilon = 0.050\n",
            "Episode 234: Total Reward = -158.08, Epsilon = 0.050\n",
            "Episode 235: Total Reward = -165.47, Epsilon = 0.050\n",
            "Episode 236: Total Reward = -176.82, Epsilon = 0.050\n",
            "Episode 237: Total Reward = -169.46, Epsilon = 0.050\n",
            "Episode 238: Total Reward = -168.35, Epsilon = 0.050\n",
            "Episode 239: Total Reward = -159.81, Epsilon = 0.050\n",
            "Episode 240: Total Reward = -165.45, Epsilon = 0.050\n",
            "Episode 241: Total Reward = -166.07, Epsilon = 0.050\n",
            "Episode 242: Total Reward = -157.87, Epsilon = 0.050\n",
            "Episode 243: Total Reward = -166.09, Epsilon = 0.050\n",
            "Episode 244: Total Reward = -168.70, Epsilon = 0.050\n",
            "Episode 245: Total Reward = -148.59, Epsilon = 0.050\n",
            "Episode 246: Total Reward = -175.29, Epsilon = 0.050\n",
            "Episode 247: Total Reward = -168.63, Epsilon = 0.050\n",
            "Episode 248: Total Reward = -179.17, Epsilon = 0.050\n",
            "Episode 249: Total Reward = -168.05, Epsilon = 0.050\n",
            "Episode 250: Total Reward = -167.23, Epsilon = 0.050\n",
            "Episode 251: Total Reward = -167.33, Epsilon = 0.050\n",
            "Episode 252: Total Reward = -178.88, Epsilon = 0.050\n",
            "Episode 253: Total Reward = -167.09, Epsilon = 0.050\n",
            "Episode 254: Total Reward = -162.84, Epsilon = 0.050\n",
            "Episode 255: Total Reward = -177.40, Epsilon = 0.050\n",
            "Episode 256: Total Reward = -174.91, Epsilon = 0.050\n",
            "Episode 257: Total Reward = -178.42, Epsilon = 0.050\n",
            "Episode 258: Total Reward = -169.60, Epsilon = 0.050\n",
            "Episode 259: Total Reward = -160.09, Epsilon = 0.050\n",
            "Episode 260: Total Reward = -168.51, Epsilon = 0.050\n",
            "Episode 261: Total Reward = -166.37, Epsilon = 0.050\n",
            "Episode 262: Total Reward = -166.65, Epsilon = 0.050\n",
            "Episode 263: Total Reward = -171.05, Epsilon = 0.050\n",
            "Episode 264: Total Reward = -168.04, Epsilon = 0.050\n",
            "Episode 265: Total Reward = -168.70, Epsilon = 0.050\n",
            "Episode 266: Total Reward = -162.53, Epsilon = 0.050\n",
            "Episode 267: Total Reward = -163.11, Epsilon = 0.050\n",
            "Episode 268: Total Reward = -173.28, Epsilon = 0.050\n",
            "Episode 269: Total Reward = -175.73, Epsilon = 0.050\n",
            "Episode 270: Total Reward = -167.88, Epsilon = 0.050\n",
            "Episode 271: Total Reward = -170.66, Epsilon = 0.050\n",
            "Episode 272: Total Reward = -160.80, Epsilon = 0.050\n",
            "Episode 273: Total Reward = -162.21, Epsilon = 0.050\n",
            "Episode 274: Total Reward = -167.52, Epsilon = 0.050\n",
            "Episode 275: Total Reward = -167.80, Epsilon = 0.050\n",
            "Episode 276: Total Reward = -165.82, Epsilon = 0.050\n",
            "Episode 277: Total Reward = -169.51, Epsilon = 0.050\n",
            "Episode 278: Total Reward = -168.30, Epsilon = 0.050\n",
            "Episode 279: Total Reward = -167.69, Epsilon = 0.050\n",
            "Episode 280: Total Reward = -163.01, Epsilon = 0.050\n",
            "Episode 281: Total Reward = -144.44, Epsilon = 0.050\n",
            "Episode 282: Total Reward = -157.00, Epsilon = 0.050\n",
            "Episode 283: Total Reward = -176.89, Epsilon = 0.050\n",
            "Episode 284: Total Reward = -178.88, Epsilon = 0.050\n",
            "Episode 285: Total Reward = -151.52, Epsilon = 0.050\n",
            "Episode 286: Total Reward = -169.47, Epsilon = 0.050\n",
            "Episode 287: Total Reward = -178.20, Epsilon = 0.050\n",
            "Episode 288: Total Reward = -170.91, Epsilon = 0.050\n",
            "Episode 289: Total Reward = -177.16, Epsilon = 0.050\n",
            "Episode 290: Total Reward = -173.07, Epsilon = 0.050\n",
            "Episode 291: Total Reward = -155.43, Epsilon = 0.050\n",
            "Episode 292: Total Reward = -178.37, Epsilon = 0.050\n",
            "Episode 293: Total Reward = -171.29, Epsilon = 0.050\n",
            "Episode 294: Total Reward = -178.28, Epsilon = 0.050\n",
            "Episode 295: Total Reward = -176.21, Epsilon = 0.050\n",
            "Episode 296: Total Reward = -164.14, Epsilon = 0.050\n",
            "Episode 297: Total Reward = -162.43, Epsilon = 0.050\n",
            "Episode 298: Total Reward = -162.54, Epsilon = 0.050\n",
            "Episode 299: Total Reward = -175.90, Epsilon = 0.050\n",
            "Episode 300: Total Reward = -173.06, Epsilon = 0.050\n",
            "Episode 301: Total Reward = -162.32, Epsilon = 0.050\n",
            "Episode 302: Total Reward = -165.11, Epsilon = 0.050\n",
            "Episode 303: Total Reward = -163.67, Epsilon = 0.050\n",
            "Episode 304: Total Reward = -180.22, Epsilon = 0.050\n",
            "Episode 305: Total Reward = -177.81, Epsilon = 0.050\n",
            "Episode 306: Total Reward = -165.72, Epsilon = 0.050\n",
            "Episode 307: Total Reward = -179.34, Epsilon = 0.050\n",
            "Episode 308: Total Reward = -175.82, Epsilon = 0.050\n",
            "Episode 309: Total Reward = -170.65, Epsilon = 0.050\n",
            "Episode 310: Total Reward = -162.35, Epsilon = 0.050\n",
            "Episode 311: Total Reward = -168.09, Epsilon = 0.050\n",
            "Episode 312: Total Reward = -174.28, Epsilon = 0.050\n",
            "Episode 313: Total Reward = -151.68, Epsilon = 0.050\n",
            "Episode 314: Total Reward = -180.13, Epsilon = 0.050\n",
            "Episode 315: Total Reward = -172.84, Epsilon = 0.050\n",
            "Episode 316: Total Reward = -185.17, Epsilon = 0.050\n",
            "Episode 317: Total Reward = -158.38, Epsilon = 0.050\n",
            "Episode 318: Total Reward = -168.41, Epsilon = 0.050\n",
            "Episode 319: Total Reward = -159.72, Epsilon = 0.050\n",
            "Episode 320: Total Reward = -172.36, Epsilon = 0.050\n",
            "Episode 321: Total Reward = -153.10, Epsilon = 0.050\n",
            "Episode 322: Total Reward = -180.43, Epsilon = 0.050\n",
            "Episode 323: Total Reward = -173.72, Epsilon = 0.050\n",
            "Episode 324: Total Reward = -175.58, Epsilon = 0.050\n",
            "Episode 325: Total Reward = -194.03, Epsilon = 0.050\n",
            "Episode 326: Total Reward = -178.95, Epsilon = 0.050\n",
            "Episode 327: Total Reward = -167.69, Epsilon = 0.050\n",
            "Episode 328: Total Reward = -171.11, Epsilon = 0.050\n",
            "Episode 329: Total Reward = -173.74, Epsilon = 0.050\n",
            "Episode 330: Total Reward = -170.35, Epsilon = 0.050\n",
            "Episode 331: Total Reward = -168.32, Epsilon = 0.050\n",
            "Episode 332: Total Reward = -138.41, Epsilon = 0.050\n",
            "Episode 333: Total Reward = -152.37, Epsilon = 0.050\n",
            "Episode 334: Total Reward = -166.40, Epsilon = 0.050\n",
            "Episode 335: Total Reward = -167.68, Epsilon = 0.050\n",
            "Episode 336: Total Reward = -166.42, Epsilon = 0.050\n",
            "Episode 337: Total Reward = -146.76, Epsilon = 0.050\n",
            "Episode 338: Total Reward = -167.87, Epsilon = 0.050\n",
            "Episode 339: Total Reward = -164.16, Epsilon = 0.050\n",
            "Episode 340: Total Reward = -174.87, Epsilon = 0.050\n",
            "Episode 341: Total Reward = -165.16, Epsilon = 0.050\n",
            "Episode 342: Total Reward = -152.49, Epsilon = 0.050\n",
            "Episode 343: Total Reward = -167.64, Epsilon = 0.050\n",
            "Episode 344: Total Reward = -169.62, Epsilon = 0.050\n",
            "Episode 345: Total Reward = -165.67, Epsilon = 0.050\n",
            "Episode 346: Total Reward = -168.17, Epsilon = 0.050\n",
            "Episode 347: Total Reward = -161.75, Epsilon = 0.050\n",
            "Episode 348: Total Reward = -154.87, Epsilon = 0.050\n",
            "Episode 349: Total Reward = -152.57, Epsilon = 0.050\n",
            "Episode 350: Total Reward = -170.57, Epsilon = 0.050\n",
            "Episode 351: Total Reward = -164.10, Epsilon = 0.050\n",
            "Episode 352: Total Reward = -159.76, Epsilon = 0.050\n",
            "Episode 353: Total Reward = -182.01, Epsilon = 0.050\n",
            "Episode 354: Total Reward = -172.33, Epsilon = 0.050\n",
            "Episode 355: Total Reward = -168.45, Epsilon = 0.050\n",
            "Episode 356: Total Reward = -167.34, Epsilon = 0.050\n",
            "Episode 357: Total Reward = -176.44, Epsilon = 0.050\n",
            "Episode 358: Total Reward = -169.99, Epsilon = 0.050\n",
            "Episode 359: Total Reward = -171.94, Epsilon = 0.050\n",
            "Episode 360: Total Reward = -178.71, Epsilon = 0.050\n",
            "Episode 361: Total Reward = -176.97, Epsilon = 0.050\n",
            "Episode 362: Total Reward = -171.90, Epsilon = 0.050\n",
            "Episode 363: Total Reward = -167.02, Epsilon = 0.050\n",
            "Episode 364: Total Reward = -167.76, Epsilon = 0.050\n",
            "Episode 365: Total Reward = -177.54, Epsilon = 0.050\n",
            "Episode 366: Total Reward = -161.99, Epsilon = 0.050\n",
            "Episode 367: Total Reward = -154.96, Epsilon = 0.050\n",
            "Episode 368: Total Reward = -159.80, Epsilon = 0.050\n",
            "Episode 369: Total Reward = -178.88, Epsilon = 0.050\n",
            "Episode 370: Total Reward = -178.40, Epsilon = 0.050\n",
            "Episode 371: Total Reward = -161.95, Epsilon = 0.050\n",
            "Episode 372: Total Reward = -181.63, Epsilon = 0.050\n",
            "Episode 373: Total Reward = -164.59, Epsilon = 0.050\n",
            "Episode 374: Total Reward = -195.00, Epsilon = 0.050\n",
            "Episode 375: Total Reward = -175.29, Epsilon = 0.050\n",
            "Episode 376: Total Reward = -183.32, Epsilon = 0.050\n",
            "Episode 377: Total Reward = -174.44, Epsilon = 0.050\n",
            "Episode 378: Total Reward = -167.65, Epsilon = 0.050\n",
            "Episode 379: Total Reward = -177.50, Epsilon = 0.050\n",
            "Episode 380: Total Reward = -177.40, Epsilon = 0.050\n",
            "Episode 381: Total Reward = -179.24, Epsilon = 0.050\n",
            "Episode 382: Total Reward = -168.88, Epsilon = 0.050\n",
            "Episode 383: Total Reward = -177.90, Epsilon = 0.050\n",
            "Episode 384: Total Reward = -171.23, Epsilon = 0.050\n",
            "Episode 385: Total Reward = -173.67, Epsilon = 0.050\n",
            "Episode 386: Total Reward = -173.02, Epsilon = 0.050\n",
            "Episode 387: Total Reward = -167.11, Epsilon = 0.050\n",
            "Episode 388: Total Reward = -177.36, Epsilon = 0.050\n",
            "Episode 389: Total Reward = -162.60, Epsilon = 0.050\n",
            "Episode 390: Total Reward = -175.66, Epsilon = 0.050\n",
            "Episode 391: Total Reward = -181.93, Epsilon = 0.050\n",
            "Episode 392: Total Reward = -167.61, Epsilon = 0.050\n",
            "Episode 393: Total Reward = -173.28, Epsilon = 0.050\n",
            "Episode 394: Total Reward = -173.33, Epsilon = 0.050\n",
            "Episode 395: Total Reward = -158.78, Epsilon = 0.050\n",
            "Episode 396: Total Reward = -195.30, Epsilon = 0.050\n",
            "Episode 397: Total Reward = -194.56, Epsilon = 0.050\n",
            "Episode 398: Total Reward = -192.88, Epsilon = 0.050\n",
            "Episode 399: Total Reward = -169.92, Epsilon = 0.050\n",
            "Episode 400: Total Reward = -159.21, Epsilon = 0.050\n",
            "Episode 401: Total Reward = -190.77, Epsilon = 0.050\n",
            "Episode 402: Total Reward = -160.32, Epsilon = 0.050\n",
            "Episode 403: Total Reward = -169.94, Epsilon = 0.050\n",
            "Episode 404: Total Reward = -187.29, Epsilon = 0.050\n",
            "Episode 405: Total Reward = -167.51, Epsilon = 0.050\n",
            "Episode 406: Total Reward = -175.32, Epsilon = 0.050\n",
            "Episode 407: Total Reward = -180.30, Epsilon = 0.050\n",
            "Episode 408: Total Reward = -184.65, Epsilon = 0.050\n",
            "Episode 409: Total Reward = -192.41, Epsilon = 0.050\n",
            "Episode 410: Total Reward = -167.44, Epsilon = 0.050\n",
            "Episode 411: Total Reward = -186.63, Epsilon = 0.050\n",
            "Episode 412: Total Reward = -166.01, Epsilon = 0.050\n",
            "Episode 413: Total Reward = -157.95, Epsilon = 0.050\n",
            "Episode 414: Total Reward = -149.19, Epsilon = 0.050\n",
            "Episode 415: Total Reward = -154.56, Epsilon = 0.050\n",
            "Episode 416: Total Reward = -176.28, Epsilon = 0.050\n",
            "Episode 417: Total Reward = -166.25, Epsilon = 0.050\n",
            "Episode 418: Total Reward = -164.75, Epsilon = 0.050\n",
            "Episode 419: Total Reward = -182.72, Epsilon = 0.050\n",
            "Episode 420: Total Reward = -164.91, Epsilon = 0.050\n",
            "Episode 421: Total Reward = -163.60, Epsilon = 0.050\n",
            "Episode 422: Total Reward = -157.91, Epsilon = 0.050\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-2604066676.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepsilon_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-5-2604066676.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import gymnasium\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "# Set up environment and device\n",
        "env = gymnasium.make(\"MountainCar-v0\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Neural Network (Q-network)\n",
        "class Brain(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize model, optimizer, loss\n",
        "brain = Brain().to(device)\n",
        "optimizer = optim.Adam(brain.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Hyperparameters\n",
        "gamma = 0.99\n",
        "epsilon = 1.0\n",
        "epsilon_min = 0.05\n",
        "epsilon_decay = 0.98\n",
        "memory = deque(maxlen=10000)\n",
        "batch_size = 64\n",
        "\n",
        "# Choose action using ε-greedy policy\n",
        "def choose_action(state):\n",
        "    if random.random() < epsilon:\n",
        "        return env.action_space.sample()\n",
        "    else:\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            return brain(state_tensor).argmax().item()\n",
        "\n",
        "# Training function\n",
        "def train():\n",
        "    if len(memory) < 1000:\n",
        "        return\n",
        "\n",
        "    batch = random.sample(memory, batch_size)\n",
        "    states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "    states = torch.FloatTensor(states).to(device)\n",
        "    actions = torch.LongTensor(actions).unsqueeze(1).to(device)\n",
        "    rewards = torch.FloatTensor(rewards).to(device)\n",
        "    next_states = torch.FloatTensor(next_states).to(device)\n",
        "    dones = torch.BoolTensor(dones).to(device)\n",
        "\n",
        "    q_values = brain(states).gather(1, actions).squeeze()\n",
        "    next_q_values = brain(next_states).max(1)[0]\n",
        "    targets = rewards + gamma * next_q_values * (~dones)\n",
        "\n",
        "    loss = loss_fn(q_values, targets.detach())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Training loop\n",
        "for episode in range(1000):\n",
        "    state, _ = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = choose_action(state)\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        # Optional reward shaping (can improve learning)\n",
        "        reward += abs(next_state[0] + 0.5)\n",
        "\n",
        "        memory.append((state, action, reward, next_state, done))\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        train()\n",
        "\n",
        "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "    print(f\"Episode {episode + 1}: Total Reward = {total_reward:.2f}, Epsilon = {epsilon:.3f}\")\n",
        "\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B71gut8cQI0L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}